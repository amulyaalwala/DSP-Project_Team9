{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Phase2_VGG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMyrnPdsBKRd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgJ-IJOLBaqv"
      },
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOiQq5O8BlkF"
      },
      "source": [
        "# initializing VGG with its own weights,\n",
        "# include_top false means it removes top dense layers which are optimized for VGG images \n",
        "# we need to add new layers and train with our data.\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False) # here [3] is 3 channels Red blue Green\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgmd4kpoBnXl"
      },
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "#Here we Froze the weights of VGG- Meaning we are using existing features from VGG adn mixing with our dense layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQit_e33BsxF"
      },
      "source": [
        "# Model without any dense layers, features only from VGNET and direct predictions.\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(26, activation='softmax')(x) # here we have 26 output classes so i gave 5 in output layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL59G-Q_BumY"
      },
      "source": [
        "# Creating VGNET model\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igU2mZ--Bwhq",
        "outputId": "e7c52f02-c5ad-430b-a9f3-46cde27d4665"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                652314    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,367,002\n",
            "Trainable params: 652,314\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs8DijqYBy5Y"
      },
      "source": [
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.RMSprop(),\n",
        "  metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJclpULB31r",
        "outputId": "6a26c37e-a550-4144-a5cc-53c3477c4cf8"
      },
      "source": [
        "#Input needs to be (224,224)\n",
        "# we are addign data augmentation to zoom in out , and flipping horizontally\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  #  shear_range = 0.2,\n",
        "                                  #  zoom_range = 0.2,\n",
        "                                  #  horizontal_flip = True\n",
        "                                   )# add augments with horizontal flip\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)#divide by 255 to normalize/scale\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Project_Data/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 128,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Project_Data/Test',\n",
        "                                           target_size = (224, 224),\n",
        "                                             batch_size = 128,\n",
        "                                             class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2366 images belonging to 26 classes.\n",
            "Found 811 images belonging to 26 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZZ7c_aeDdmT",
        "outputId": "98882242-0630-4a91-de56-932db0fb976c"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5\n",
        "  # steps_per_epoch=128\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 61s 3s/step - loss: 6.8077 - accuracy: 0.0592 - val_loss: 3.6850 - val_accuracy: 0.1418\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 58s 3s/step - loss: 2.9673 - accuracy: 0.2443 - val_loss: 3.5062 - val_accuracy: 0.1566\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 59s 3s/step - loss: 3.0129 - accuracy: 0.2371 - val_loss: 3.5793 - val_accuracy: 0.1998\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 59s 3s/step - loss: 2.5977 - accuracy: 0.3233 - val_loss: 3.6798 - val_accuracy: 0.1973\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 57s 3s/step - loss: 2.0756 - accuracy: 0.4370 - val_loss: 3.2718 - val_accuracy: 0.2491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43HUP1ZCFWhr",
        "outputId": "af5769ea-96dd-48c6-a284-d2c2d948449b"
      },
      "source": [
        "#This did not work very will with VG net architecture.\n",
        "#Transfer learning may not always work. we need to Tweak some parameters and try it agian,\n",
        "score = model.evaluate(test_set)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 15s 2s/step - loss: 3.2718 - accuracy: 0.2491\n",
            "Test Loss: 3.271759033203125\n",
            "Test accuracy: 0.24907521903514862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2oqYZvuNkBv"
      },
      "source": [
        "#second try\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoBvkqFaNmLt"
      },
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3hfgalTNsHF"
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "x=Dense(100, activation='relu')(x)\n",
        "Dropout(0.5)(x)\n",
        "x=Dense(100, activation='relu')(x)\n",
        "prediction = Dense(26, activation='softmax')(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJZM_0PNt82"
      },
      "source": [
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeWpyH8fNv0G",
        "outputId": "343eb612-c243-47ef-e702-f95993de1708"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               2508900   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 26)                2626      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,236,314\n",
            "Trainable params: 2,521,626\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCJhLiTuNxoJ"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.RMSprop(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "callback = [earlystop]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWJFT149N2M1",
        "outputId": "3a426765-4643-45b3-f44b-64516799d77b"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5,\n",
        "  batch_size=128,\n",
        "  callbacks=callback\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 61s 3s/step - loss: 3.8181 - accuracy: 0.0558 - val_loss: 3.2258 - val_accuracy: 0.0654\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 57s 3s/step - loss: 3.1838 - accuracy: 0.0875 - val_loss: 3.2157 - val_accuracy: 0.0592\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 57s 3s/step - loss: 3.1077 - accuracy: 0.1031 - val_loss: 3.1610 - val_accuracy: 0.0777\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 57s 3s/step - loss: 2.9927 - accuracy: 0.1230 - val_loss: 3.1100 - val_accuracy: 0.0838\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 57s 3s/step - loss: 2.9199 - accuracy: 0.1306 - val_loss: 3.0759 - val_accuracy: 0.1023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxqUKHAcN4AN",
        "outputId": "be647c7a-421a-47c8-a261-5e26ee670ec0"
      },
      "source": [
        "score = model.evaluate(test_set)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 15s 2s/step - loss: 3.0759 - accuracy: 0.1023\n",
            "Test Loss: 3.0759243965148926\n",
            "Test accuracy: 0.10234278440475464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hNhuHOQN81T"
      },
      "source": [
        "#Thrid Model - Now i will only use one dense layer and one for output.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpeHPHUvN-zJ"
      },
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW8QH_1qOBhq"
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "x=Dense(50, activation='relu')(x)\n",
        "prediction = Dense(26, activation='softmax')(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6JJAWeLOE1T"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "callback = [earlystop]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrKGTJ8NOHIe",
        "outputId": "92a1a543-4267-4e04-a6b5-e8f31647ae2f"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=8,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),callbacks=callback\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "19/19 [==============================] - 60s 3s/step - loss: 2.6932 - accuracy: 0.1915 - val_loss: 2.8796 - val_accuracy: 0.1628\n",
            "Epoch 2/8\n",
            "19/19 [==============================] - 54s 3s/step - loss: 2.4677 - accuracy: 0.2756 - val_loss: 2.6992 - val_accuracy: 0.1961\n",
            "Epoch 3/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 2.2250 - accuracy: 0.3419 - val_loss: 2.5046 - val_accuracy: 0.2256\n",
            "Epoch 4/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 2.0159 - accuracy: 0.3918 - val_loss: 2.3632 - val_accuracy: 0.2676\n",
            "Epoch 5/8\n",
            "19/19 [==============================] - 52s 3s/step - loss: 1.7976 - accuracy: 0.4505 - val_loss: 2.2870 - val_accuracy: 0.2676\n",
            "Epoch 6/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.6061 - accuracy: 0.5072 - val_loss: 2.1680 - val_accuracy: 0.2922\n",
            "Epoch 7/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.4312 - accuracy: 0.5668 - val_loss: 2.1239 - val_accuracy: 0.3428\n",
            "Epoch 8/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.2895 - accuracy: 0.6128 - val_loss: 2.0350 - val_accuracy: 0.3613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCqS8DBGOJC8",
        "outputId": "5ab24553-3cbe-4865-8d48-ae6524aef31e"
      },
      "source": [
        "score = model.evaluate(test_set)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 13s 2s/step - loss: 2.0350 - accuracy: 0.3613\n",
            "Test Loss: 2.034989356994629\n",
            "Test accuracy: 0.3612823784351349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK4IYaHkVZS3"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.RMSprop(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "callback = [earlystop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7QZTY8jVZb3",
        "outputId": "93bf4fed-8941-403d-ba58-ead71ccdb303"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=8,\n",
        "  # steps_per_epoch=len(training_set),\n",
        "  # validation_steps=len(test_set)\n",
        "  callbacks=callback\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "19/19 [==============================] - 74s 3s/step - loss: 2.4126 - accuracy: 0.4159 - val_loss: 2.1998 - val_accuracy: 0.2996\n",
            "Epoch 2/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.5023 - accuracy: 0.5237 - val_loss: 2.4189 - val_accuracy: 0.2651\n",
            "Epoch 3/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.5190 - accuracy: 0.5304 - val_loss: 2.5335 - val_accuracy: 0.2589\n",
            "Epoch 4/8\n",
            "19/19 [==============================] - 50s 3s/step - loss: 1.4429 - accuracy: 0.5359 - val_loss: 2.5023 - val_accuracy: 0.2774\n",
            "Epoch 5/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.4192 - accuracy: 0.5385 - val_loss: 2.2977 - val_accuracy: 0.2972\n",
            "Epoch 6/8\n",
            "19/19 [==============================] - 51s 3s/step - loss: 1.3890 - accuracy: 0.5469 - val_loss: 2.2306 - val_accuracy: 0.3292\n",
            "Epoch 00006: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ4hX5yuVZfp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Zik7StOK_F"
      },
      "source": [
        "#This model Fitted Best compared to the model whit direct predictions of our data with VGG \n",
        "#it worked better than the one with 2 dense layers."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh0okUQONbR"
      },
      "source": [
        "# Its good to use simple models than complex models with more features."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FQ4Fh1ROPCI"
      },
      "source": [
        "# Here we explored the Power of transfer learning, by using existing features from VGG\n",
        "# and adding only one dense layer other than output we saved a lot of compute power and time and\n",
        "#achieved great accuracy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4F5HPxPOQyV"
      },
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL66cd4X1aS"
      },
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEvyZvDcX-ca",
        "outputId": "058f83c0-3921-4c10-e0e7-cf9a3360f9a8"
      },
      "source": [
        "\n",
        "last_layer = vgg.get_layer('block4_pool')\n",
        "\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = Flatten()(last_output)\n",
        "\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "# x=Dense(100, activation='relu')(x)\n",
        "# Dropout(0.5)(x)\n",
        "x=Dense(100, activation='relu')(x)\n",
        "Dropout(0.5)(x)\n",
        "prediction = Dense(26, activation='softmax')(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 14, 14, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkbG1W_NYiiX",
        "outputId": "f9b6750c-de59-4535-cdc1-3d0069ad12e0"
      },
      "source": [
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.RMSprop(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "callback = [earlystop]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               10035300  \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 26)                2626      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,673,190\n",
            "Trainable params: 10,037,926\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNc9XAA4ZC0F",
        "outputId": "79f3f5b6-69a0-4f18-a85d-d326dc05c5b8"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5,\n",
        "  batch_size=128,\n",
        "  callbacks=callback\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 53s 3s/step - loss: 19.9695 - accuracy: 0.0545 - val_loss: 3.2572 - val_accuracy: 0.0382\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 50s 3s/step - loss: 3.3698 - accuracy: 0.0600 - val_loss: 3.2838 - val_accuracy: 0.0407\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 50s 3s/step - loss: 3.2715 - accuracy: 0.0630 - val_loss: 3.2626 - val_accuracy: 0.0382\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 50s 3s/step - loss: 3.2784 - accuracy: 0.0558 - val_loss: 3.2586 - val_accuracy: 0.0382\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 50s 3s/step - loss: 3.2443 - accuracy: 0.0587 - val_loss: 3.2611 - val_accuracy: 0.0395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xHa4iWOZX6p"
      },
      "source": [
        "# we can see that Image net is not a great fit for our dataset, even after training and removing some layers."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}